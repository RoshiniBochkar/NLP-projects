{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5HsT/Qtqini9KF0dbR13t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshiniBochkar/NLP-projects/blob/main/amazon_food_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "import pandas as pd\n",
        "# Initialize SageMaker session\n",
        "sagemaker_session = sagemaker.Session()\n",
        "# Get the SageMaker execution role\n",
        "role = sagemaker.get_execution_role()\n",
        "# 53 bucket for storing data\n",
        "bucket = sagemaker_session.default_bucket()\n",
        "prefix = \"nip-model-demo\""
      ],
      "metadata": {
        "id": "NkUWeNCHutLQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare and Upload Data**"
      ],
      "metadata": {
        "id": "za5hNSoswAo8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2DZ_8Pq2rBZB"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Reviews.csv\")\n",
        "df = df[[\"Text\", \"Score\"]].dropna()\n",
        "df[\"Sentiment\"] = df[\"Score\"].apply(lambda x: 1 if x > 3 else 0)\n",
        "df = df[[\"Text\", \"Sentiment\"]]\n",
        "df.to_csv(\"processed_reviews.csv\", index=False)\n",
        "s3 = boto3.client(\"s3\")\n",
        "s3.upload_file(\"processed_reviews.csv\", bucket, f\"{prefix}/processed_reviews.csv\")\n",
        "s3_train_data = f\"s3://{bucket}/{prefix}/processed_reviews.csv\"\n",
        "print(\"Data uploaded to:\", s3_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create the Trainina Script**"
      ],
      "metadata": {
        "id": "TPf5hqOyw2Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNlUaYtx5V2E",
        "outputId": "0b5bea33-fc97-49a8-c819-0e61a408c885"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument (\"--train_data\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
        "  args = parser.parse_args()\n",
        "  train_data_path = os.path.join(args.train_data, \"processed_reviews.csv\")\n",
        "  df = pd.read_csv(train_data_path)\n",
        "X = df[\"Text\"]\n",
        "y = df[\"Sentiment\"]"
      ],
      "metadata": {
        "id": "pX9U14xH0556"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\")),\n",
        "     (\"clf\", LogisticRegression)\n",
        "])\n",
        "pipeline.fit(X,y)\n",
        "model_path = os.path.join(\"/opt/ml/model\", \"model.joblib\")\n",
        "joblib.dump(pipeline, model_path)\n",
        "print (\"Model saved at\", model_path)\n",
        "if __name__ == \"__main__\":\n",
        "  train()"
      ],
      "metadata": {
        "id": "VxZKVAq3zezM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the Model in SageMaker**"
      ],
      "metadata": {
        "id": "EQhuRVYjz4me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker. sklearn.estimator import SKLearn\n",
        "sklearn_estimator = SKLearn(\n",
        "    entry_point=\"train.py\",\n",
        "    framework_version=\"0.23-1\",\n",
        "    instance_type=\"ml.m5.large\",\n",
        "    role=role,\n",
        "    sagemaker_session=sagemaker_session,\n",
        ")\n",
        "# Train the model on SageMaker\n",
        "sklearn_estimator.fit({\"train\": s3_train_data})"
      ],
      "metadata": {
        "id": "P1all2zg0Beq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploy the Model**"
      ],
      "metadata": {
        "id": "ONwEs_Ae0XiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile inference.py\n",
        "import joblib\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "def model_fn(model_dir):\n",
        "  model_path = os.path.join(model_dir, \"model.joblib\")\n",
        "  return joblib. load (model_path)\n",
        "def input_fn(request_body, request_content_type):\n",
        "  if request_content_type == \"application/json\":\n",
        "    data = json.loads(request_body)\n",
        "    return pd.DataFrame(data, columns=[\"Text\"])\n",
        "  else:\n",
        "    raise ValueError (\"Unsupported content type: 0)\".formatrequest_content_type))\n",
        "def predict_fn(input_data, model):\n",
        "  return model.predict(input_data[\"Text\"]).tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWy1iUzh0XW2",
        "outputId": "901a0c73-ebfb-4b6b-86f1-bb44a117621a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing inference.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploy the Model in SageMaker**"
      ],
      "metadata": {
        "id": "oOQBPgnF05Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker. sklearn.model import SKLearnModel\n",
        "model_data = sklearn_estimator.model_data\n",
        "sklearn_model = SKLearnModel(\n",
        "    model_data=model_data,\n",
        "    role=role,\n",
        "    entry_point=\"inference.py\",\n",
        "    framework_version=\"0.23-1\",\n",
        "    sagemaker_session=sagemaker_session,\n",
        ")\n",
        "predictor = sklearn_model.deploy(instance_type=\"ml.m5.large\", initial_instance_count=1)"
      ],
      "metadata": {
        "id": "bj-zUpcN0XUE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "test_data = json.dumps([\"This product is amazing!\", \"Worst product ever.\"])\n",
        "response = predictor.predict(test_data)\n",
        "print(\"Predictions:\", response)"
      ],
      "metadata": {
        "id": "1i8r2_pv0XRS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean Up Resources**"
      ],
      "metadata": {
        "id": "bg7tYoX83V6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.delete_endpoint()"
      ],
      "metadata": {
        "id": "kZgwGePi3cwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "--lSmypm2A3b"
      }
    }
  ]
}